<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Your Name</title>
  <style>
    /* ---- Global Typography & Colors ---- */
    html {
      font-size: 18px;
    }
    body {
      margin: 0;
      font-family: "Times New Roman", Times, serif; /* closely matches screenshot */
      background-color: #ffffff;
      color: #000000;
      line-height: 1.55;
    }

    /* ---- Layout ---- */
    .container {
      max-width: 680px; /* similar reading width */
      margin: 0 auto;
      padding: 2.5rem 1.25rem;
    }

    /* ---- Headings ---- */
    h1 {
      margin-top: 0;
      margin-bottom: 1.2rem;
      font-size: 2rem; /* visually comparable to screenshot */
      font-weight: 700;
    }

    h2 {
      margin: 2.2rem 0 0.8rem;
      font-size: 1.25rem;
      font-weight: 700;
    }

    /* ---- Links ---- */
    a {
      color: #0066cc; /* default Safari/Chrome blue */
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    /* ---- Lists ---- */
    ul {
      padding-left: 1.2rem;
      margin-top: 0.4rem;
    }
    ul li {
      margin-bottom: 0.3rem;
    }

    /* inline separators between anchor links */
    .inline-links a:not(:last-child)::after {
      content: " · ";
      color: #000;
    }
  </style>
</head>
<body>
  <main class="container">
    <!-- Name Header -->
    <h1>Your Name</h1>

    <!-- Profile links (Google Scholar, GitHub, etc.) -->
    <div class="inline-links">
      <a href="#">Google Scholar</a>
      <a href="#">GitHub</a>
      <a href="#">Twitter</a>
      <a href="#">Email</a>
    </div>

    <!-- Intro paragraph -->
    <p>
      I'm currently taking a short break from frontier AI research to solve OCR for
      Sanskrit. I feel it critical that the classical Indian literary canon be
      immortalized in the training corpus for superintelligence.
    </p>

    <p>
      At OpenAI, I helped train GPT‑5 and future models. I graduated from Carnegie
      Mellon University in 2023 with an honors thesis on semantics in
      multimodal LLMs.
    </p>

    <!-- Experience -->
    <h2>Experience</h2>
    <ul>
      <li><strong>OpenAI:</strong> Explored model architecture questions spanning Pre‑training, RL, and Inference</li>
      <li><strong>Reworkd (YC S23):</strong> Built a multimodal web agent generating 5k lines of code weekly</li>
      <li><strong>Microsoft AI:</strong> Fine‑tuned language models to automate enterprise‑scale data annotation</li>
    </ul>

    <!-- Selected Publications -->
    <h2>Selected Publications</h2>
    <ul>
      <li><em>gzip Predicts Data‑dependent Scaling Laws</em> (<a href="#">ArXiv&nbsp;2024</a>)</li>
      <li><em>Multimodal Learning Without Multimodal Data</em>: Guarantees and Applications (<a href="#">ICLR&nbsp;2024</a>)</li>
      <li><em>Towards Vision‑Language Mechanistic Interpretability</em>: a Causal Tracing Tool for BLIP (<a href="#">ICCV&nbsp;2023 –&nbsp;CLVL</a>)</li>
      <li><em>Cross‑modal Attention Congruence Regularization</em> for Vision‑Language Relation Alignment (<a href="#">ACL&nbsp;2023</a>)</li>
      <li><em>Syntax‑guided Neural Module Distillation</em> to Probe Compositionality in Sentence Embeddings (<a href="#">EACL&nbsp;2023</a>)</li>
      <li>A Family of Cognitively Realistic Parsing Environments for Deep Reinforcement Learning (<a href="#">NeurIPS&nbsp;2021 – Deep RL</a>)</li>
    </ul>

    <!-- Featured Projects -->
    <h2>Featured Projects</h2>
    <ul>
      <li><a href="#">LlamaGym</a>: Fine‑tune LLM agents with online reinforcement learning</li>
      <li><a href="#">Tarsier</a>: Vision utilities for agents to interact with the web</li>
      <li><a href="#">veda.dev</a>: Morphology visualizer for Sanskrit literature research &amp; education</li>
    </ul>

    <!-- Fun Facts -->
    <h2>Fun Facts</h2>
    <ul>
      <li>Placeholder fact #1</li>
      <li>Placeholder fact #2</li>
    </ul>
  </main>
</body>
</html>
